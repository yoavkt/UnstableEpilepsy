{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/epi9/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "from epilepsy_prediction import load_model, data_preprocess\n",
    "from fuse.eval.metrics.metrics_common import  CI\n",
    "\n",
    "from copy import deepcopy\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from collections import OrderedDict\n",
    "from fuse.eval.metrics.metrics_common import GroupAnalysis, CI, Filter\n",
    "from fuse.eval.metrics.metrics_model_comparison import PairedBootstrap\n",
    "from fuse.eval.metrics.classification.metrics_classification_common import (\n",
    "    MetricAUCPR,\n",
    "    MetricAUCROC,\n",
    "    MetricAccuracy,\n",
    "    MetricConfusion,\n",
    "    MetricConfusionMatrix,\n",
    "    MetricBSS,\n",
    "    MetricROCCurve,\n",
    ")\n",
    "from fuse.eval.metrics.classification.metrics_model_comparison_common import (\n",
    "    MetricDelongsTest,\n",
    "    MetricMcnemarsTest,\n",
    ")\n",
    "from fuse.eval.evaluator import EvaluatorDefault\n",
    "\n",
    "seed =543463469"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_fuse_data(clf,clf2,X,y):\n",
    "    res = pd.DataFrame(columns=['pred','target','id'])\n",
    "    res['id']=X.index\n",
    "    res['pred1'] = clf.predict_proba(X)[:,1].squeeze()\n",
    "    res['pred2'] = clf2.predict_proba(X)[:,1].squeeze()\n",
    "    res['target'] = y.astype(int).values  \n",
    "    return res\n",
    "\n",
    "def fuse_string(results):\n",
    "    sum = []\n",
    "    for k,v in results['metrics'].items():\n",
    "        if 'auc' in k:\n",
    "            sum.append(k + f': {v['mean']:.2f} (upper: {v['conf_upper']:.2f}, lower: {v['conf_lower']:.2f})')\n",
    "        if 'mcnemar' or 'delong' in k:\n",
    "            sum.append(k + f': {v['p_value']:.2f}')\n",
    "    return sum\n",
    "\n",
    "def load_data(drug_name,file_name='/Users/yoavkt/Documents/epilepsy_data/{}_data.pkl'):\n",
    "    data = pd.read_pickle(file_name.format(drug_name))\n",
    "    return data['X'],data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_name=\"carbamazepine\"\n",
    "clf_mk = load_model(drug_name)\n",
    "drug_name=\"est_carba\"\n",
    "clf_bi = load_model(drug_name)\n",
    "drug_name = 'carbamazepine'\n",
    "X,y = load_data(drug_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7411711952961847\n"
     ]
    }
   ],
   "source": [
    "auc = metrics.roc_auc_score(y, clf_mk.predict_proba(X)[:,1])\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6307010834803918\n"
     ]
    }
   ],
   "source": [
    "auc = metrics.roc_auc_score(y, clf_bi.predict_proba(X)[:,1])\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spe_out_come = '/Users/yoavkt/Documents/outcome_break_vals.csv'\n",
    "df_spec = pd.read_csv(spe_out_come)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = OrderedDict([\n",
    "            (\"auc\", CI(MetricAUCROC(pred=\"pred\", target=\"target\"), \n",
    "                       stratum=\"target\", rnd_seed=seed)),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pvalue      0.03806366960413442\n",
      "statistic   71.0\n"
     ]
    }
   ],
   "source": [
    "mat = confusion_matrix(y == clf_bi.predict(X), y==clf_mk.predict(X))\n",
    "tes = mcnemar(mat)\n",
    "print(tes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = OrderedDict([\n",
    "            (\"auc1\", CI(MetricAUCROC(pred=\"pred1\", target=\"target\"), \n",
    "                       stratum=\"target\", rnd_seed=seed)),\n",
    "            (\"auc2\", CI(MetricAUCROC(pred=\"pred2\", target=\"target\"), \n",
    "                       stratum=\"target\", rnd_seed=seed)),\n",
    "            (\"mcnemar_test\", \n",
    "            MetricMcnemarsTest(pred1=\"pred1\", pred2=\"pred2\",target=\"target\")),\n",
    "            ('delong_test',\n",
    "            MetricDelongsTest(pred1=\"pred1\", pred2=\"pred2\",target=\"target\"))\n",
    "        ])\n",
    "evaluator = EvaluatorDefault()\n",
    "results = evaluator.eval(ids=None, data=prepare_fuse_data(clf_bi,clf_mk,X,y), metrics=metrics) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'metrics': {'auc1': {'org': 0.6307010834803918, 'mean': 0.6305202378108457, 'std': 0.013209371726008591, 'conf_interval': 95, 'conf_lower': 0.6045142447617653, 'conf_upper': 0.655997865404918}, 'auc2': {'org': 0.6307010834803918, 'mean': 0.6305202378108457, 'std': 0.013209371726008591, 'conf_interval': 95, 'conf_lower': 0.6045142447617653, 'conf_upper': 0.655997865404918}, 'mcnemars_test': {'p_value': 1.0, 'statistic': 0.0, 'n1': 0.0, 'n2': 0.0}, 'delong_test': {'p_value': 2.2683800040159284e-16, 'z': -8.206971173643009, 'auc1': 0.6307010834803918, 'auc2': 0.7411711952961847, 'cov11': 0.00017924887655622966, 'cov12': 7.731947510668091e-05, 'cov22': 0.00015657571232559572}}}\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('epi9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ddd9f49c652c6d182f69755b7ee5e124f86cbddecfc26f23757e5e4f41f4cab8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
