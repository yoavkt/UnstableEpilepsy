{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from epilepsy_prediction import load_prediction_model, data_preprocess,fuse_string,evaluate_model,load_imputation_model\n",
    "from epilepsy_prediction.imputation import column_imputer\n",
    "\n",
    "from copy import deepcopy\n",
    "from pandas import read_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the model, we can select between: Carbamazepine, Gabapentin, Lamotrigine, Levetiracetam, Oxcarbazepine, Phenytoin,Topiramate,Valproate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(change_name_file,data_file_name,outcome_col=\"outcome\"):\n",
    "    data_df = pd.read_csv(data_file_name, index_col=0)\n",
    "    new_name_df = pd.read_csv(change_name_file,index_col=0)\n",
    "    data_df.rename(new_name_df['marketscan'].to_dict(),inplace=True,axis=1)\n",
    "    y_train = data_df.loc[data_df[\"test_train\"]==\"train\",outcome_col]\n",
    "    X_train = data_df.loc[data_df[\"test_train\"]==\"train\",~( data_df.columns.isin([outcome_col,\"test_train\"]))]\n",
    "    y_test = data_df.loc[~(data_df[\"test_train\"]==\"train\"),outcome_col]\n",
    "    X_test = data_df.loc[~(data_df[\"test_train\"]==\"train\"),~ (data_df.columns.isin([outcome_col,\"test_train\"]))]\n",
    "    return X_train,y_train,X_test,y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_name_file=r\"C:\\\\Users\\Anastassia Kolde\\\\Documents\\\\Israel secondment\\\\dictionary_19.01.23.csv\"\n",
    "data_file_name = r\"C:\\\\Users\\Anastassia Kolde\\\\Documents\\\\Israel secondment\\\\Data\\test_train_epilepsy_19.01.23.csv\"\n",
    "X_train,y_train,X_test,y_test = load_data(change_name_file,data_file_name, outcome_col=\"outcome_any\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the correctness of input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name_tbl = read_csv(r\"C:\\\\Users\\Anastassia Kolde\\\\Documents\\\\Israel secondment\\\\dictionary_19.01.23.csv\")\n",
    "feature_names = col_name_tbl.iloc[:, 1]\n",
    "assert not all(X_train.columns.isin(feature_names)), \"Indeed some features can be missing\"\n",
    "assert all(feature_names.isin(X_train.columns)), \"Some features is missing from training data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_name=\"carbamazepine\"\n",
    "clf = load_prediction_model(drug_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_preprocess(X_train,impute_drug=drug_name,replace_mean=True)\n",
    "Xs = data_preprocess(X_test,impute_drug=drug_name,replace_mean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADMISSION_EP_count</th>\n",
       "      <th>ADMISSION_EP_daysToInddate_min</th>\n",
       "      <th>ADMISSION_EP_indicator</th>\n",
       "      <th>ANY_ADVERSE_EVENT_EP_count</th>\n",
       "      <th>ANY_ADVERSE_EVENT_EP_daysToInddate_min</th>\n",
       "      <th>ANY_ADVERSE_EVENT_EP_indicator</th>\n",
       "      <th>ANY_EEG_count</th>\n",
       "      <th>ANY_EEG_daysToInddate_min</th>\n",
       "      <th>ANY_EEG_indicator</th>\n",
       "      <th>CARBAMAZEPINE_daysToInddate_min</th>\n",
       "      <th>...</th>\n",
       "      <th>stdprov_Therapy (Physical)_count</th>\n",
       "      <th>stdprov_Thoracic Surgery_count</th>\n",
       "      <th>stdprov_Transplant Surgery_count</th>\n",
       "      <th>stdprov_Transportation_count</th>\n",
       "      <th>stdprov_Traumatic Surgery_count</th>\n",
       "      <th>stdprov_Treatment Center_count</th>\n",
       "      <th>stdprov_Urgent Care Facility_count</th>\n",
       "      <th>stdprov_Urology_count</th>\n",
       "      <th>stdprov_Vision Center_count</th>\n",
       "      <th>treatment_arm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EGVD004251_2007-12-18</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGVD008736_2019-05-31</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGVD010712_2005-04-13</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGVD011701_2005-01-24</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGVD015490_2019-09-16</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGVD959888_2018-05-14</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGVD961237_2009-04-20</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGVD961237_2014-06-25</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGVD990020_2016-04-04</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGVD999649_2013-04-16</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>588 rows × 751 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ADMISSION_EP_count  ADMISSION_EP_daysToInddate_min  \\\n",
       "id                                                                          \n",
       "EGVD004251_2007-12-18                   0                             NaN   \n",
       "EGVD008736_2019-05-31                   0                             NaN   \n",
       "EGVD010712_2005-04-13                   0                             NaN   \n",
       "EGVD011701_2005-01-24                   0                             NaN   \n",
       "EGVD015490_2019-09-16                   0                             NaN   \n",
       "...                                   ...                             ...   \n",
       "EGVD959888_2018-05-14                   0                             NaN   \n",
       "EGVD961237_2009-04-20                   0                             NaN   \n",
       "EGVD961237_2014-06-25                   0                             NaN   \n",
       "EGVD990020_2016-04-04                   0                             NaN   \n",
       "EGVD999649_2013-04-16                   1                             NaN   \n",
       "\n",
       "                       ADMISSION_EP_indicator  ANY_ADVERSE_EVENT_EP_count  \\\n",
       "id                                                                          \n",
       "EGVD004251_2007-12-18                   False                         NaN   \n",
       "EGVD008736_2019-05-31                   False                         NaN   \n",
       "EGVD010712_2005-04-13                   False                         NaN   \n",
       "EGVD011701_2005-01-24                   False                         NaN   \n",
       "EGVD015490_2019-09-16                   False                         NaN   \n",
       "...                                       ...                         ...   \n",
       "EGVD959888_2018-05-14                   False                         NaN   \n",
       "EGVD961237_2009-04-20                   False                         NaN   \n",
       "EGVD961237_2014-06-25                   False                         NaN   \n",
       "EGVD990020_2016-04-04                   False                         NaN   \n",
       "EGVD999649_2013-04-16                    True                         NaN   \n",
       "\n",
       "                       ANY_ADVERSE_EVENT_EP_daysToInddate_min  \\\n",
       "id                                                              \n",
       "EGVD004251_2007-12-18                                     NaN   \n",
       "EGVD008736_2019-05-31                                     NaN   \n",
       "EGVD010712_2005-04-13                                     NaN   \n",
       "EGVD011701_2005-01-24                                     NaN   \n",
       "EGVD015490_2019-09-16                                     NaN   \n",
       "...                                                       ...   \n",
       "EGVD959888_2018-05-14                                     NaN   \n",
       "EGVD961237_2009-04-20                                     NaN   \n",
       "EGVD961237_2014-06-25                                     NaN   \n",
       "EGVD990020_2016-04-04                                     NaN   \n",
       "EGVD999649_2013-04-16                                     NaN   \n",
       "\n",
       "                       ANY_ADVERSE_EVENT_EP_indicator  ANY_EEG_count  \\\n",
       "id                                                                     \n",
       "EGVD004251_2007-12-18                             NaN            NaN   \n",
       "EGVD008736_2019-05-31                             NaN            NaN   \n",
       "EGVD010712_2005-04-13                             NaN            NaN   \n",
       "EGVD011701_2005-01-24                             NaN            NaN   \n",
       "EGVD015490_2019-09-16                             NaN            NaN   \n",
       "...                                               ...            ...   \n",
       "EGVD959888_2018-05-14                             NaN            NaN   \n",
       "EGVD961237_2009-04-20                             NaN            NaN   \n",
       "EGVD961237_2014-06-25                             NaN            NaN   \n",
       "EGVD990020_2016-04-04                             NaN            NaN   \n",
       "EGVD999649_2013-04-16                             NaN            NaN   \n",
       "\n",
       "                       ANY_EEG_daysToInddate_min  ANY_EEG_indicator  \\\n",
       "id                                                                    \n",
       "EGVD004251_2007-12-18                        NaN                NaN   \n",
       "EGVD008736_2019-05-31                        NaN                NaN   \n",
       "EGVD010712_2005-04-13                        NaN                NaN   \n",
       "EGVD011701_2005-01-24                        NaN                NaN   \n",
       "EGVD015490_2019-09-16                        NaN                NaN   \n",
       "...                                          ...                ...   \n",
       "EGVD959888_2018-05-14                        NaN                NaN   \n",
       "EGVD961237_2009-04-20                        NaN                NaN   \n",
       "EGVD961237_2014-06-25                        NaN                NaN   \n",
       "EGVD990020_2016-04-04                        NaN                NaN   \n",
       "EGVD999649_2013-04-16                        NaN                NaN   \n",
       "\n",
       "                       CARBAMAZEPINE_daysToInddate_min  ...  \\\n",
       "id                                                      ...   \n",
       "EGVD004251_2007-12-18                              NaN  ...   \n",
       "EGVD008736_2019-05-31                              NaN  ...   \n",
       "EGVD010712_2005-04-13                              NaN  ...   \n",
       "EGVD011701_2005-01-24                              NaN  ...   \n",
       "EGVD015490_2019-09-16                              NaN  ...   \n",
       "...                                                ...  ...   \n",
       "EGVD959888_2018-05-14                              NaN  ...   \n",
       "EGVD961237_2009-04-20                              NaN  ...   \n",
       "EGVD961237_2014-06-25                              NaN  ...   \n",
       "EGVD990020_2016-04-04                              NaN  ...   \n",
       "EGVD999649_2013-04-16                              NaN  ...   \n",
       "\n",
       "                       stdprov_Therapy (Physical)_count  \\\n",
       "id                                                        \n",
       "EGVD004251_2007-12-18                                 0   \n",
       "EGVD008736_2019-05-31                                 0   \n",
       "EGVD010712_2005-04-13                                 0   \n",
       "EGVD011701_2005-01-24                                 0   \n",
       "EGVD015490_2019-09-16                                 0   \n",
       "...                                                 ...   \n",
       "EGVD959888_2018-05-14                                 0   \n",
       "EGVD961237_2009-04-20                                 0   \n",
       "EGVD961237_2014-06-25                                 0   \n",
       "EGVD990020_2016-04-04                                 0   \n",
       "EGVD999649_2013-04-16                                 0   \n",
       "\n",
       "                       stdprov_Thoracic Surgery_count  \\\n",
       "id                                                      \n",
       "EGVD004251_2007-12-18                               0   \n",
       "EGVD008736_2019-05-31                               0   \n",
       "EGVD010712_2005-04-13                               0   \n",
       "EGVD011701_2005-01-24                               0   \n",
       "EGVD015490_2019-09-16                               0   \n",
       "...                                               ...   \n",
       "EGVD959888_2018-05-14                               0   \n",
       "EGVD961237_2009-04-20                               0   \n",
       "EGVD961237_2014-06-25                               0   \n",
       "EGVD990020_2016-04-04                               0   \n",
       "EGVD999649_2013-04-16                               0   \n",
       "\n",
       "                       stdprov_Transplant Surgery_count  \\\n",
       "id                                                        \n",
       "EGVD004251_2007-12-18                               NaN   \n",
       "EGVD008736_2019-05-31                               NaN   \n",
       "EGVD010712_2005-04-13                               NaN   \n",
       "EGVD011701_2005-01-24                               NaN   \n",
       "EGVD015490_2019-09-16                               NaN   \n",
       "...                                                 ...   \n",
       "EGVD959888_2018-05-14                               NaN   \n",
       "EGVD961237_2009-04-20                               NaN   \n",
       "EGVD961237_2014-06-25                               NaN   \n",
       "EGVD990020_2016-04-04                               NaN   \n",
       "EGVD999649_2013-04-16                               NaN   \n",
       "\n",
       "                       stdprov_Transportation_count  \\\n",
       "id                                                    \n",
       "EGVD004251_2007-12-18                           NaN   \n",
       "EGVD008736_2019-05-31                           NaN   \n",
       "EGVD010712_2005-04-13                           NaN   \n",
       "EGVD011701_2005-01-24                           NaN   \n",
       "EGVD015490_2019-09-16                           NaN   \n",
       "...                                             ...   \n",
       "EGVD959888_2018-05-14                           NaN   \n",
       "EGVD961237_2009-04-20                           NaN   \n",
       "EGVD961237_2014-06-25                           NaN   \n",
       "EGVD990020_2016-04-04                           NaN   \n",
       "EGVD999649_2013-04-16                           NaN   \n",
       "\n",
       "                       stdprov_Traumatic Surgery_count  \\\n",
       "id                                                       \n",
       "EGVD004251_2007-12-18                              NaN   \n",
       "EGVD008736_2019-05-31                              NaN   \n",
       "EGVD010712_2005-04-13                              NaN   \n",
       "EGVD011701_2005-01-24                              NaN   \n",
       "EGVD015490_2019-09-16                              NaN   \n",
       "...                                                ...   \n",
       "EGVD959888_2018-05-14                              NaN   \n",
       "EGVD961237_2009-04-20                              NaN   \n",
       "EGVD961237_2014-06-25                              NaN   \n",
       "EGVD990020_2016-04-04                              NaN   \n",
       "EGVD999649_2013-04-16                              NaN   \n",
       "\n",
       "                       stdprov_Treatment Center_count  \\\n",
       "id                                                      \n",
       "EGVD004251_2007-12-18                             NaN   \n",
       "EGVD008736_2019-05-31                             NaN   \n",
       "EGVD010712_2005-04-13                             NaN   \n",
       "EGVD011701_2005-01-24                             NaN   \n",
       "EGVD015490_2019-09-16                             NaN   \n",
       "...                                               ...   \n",
       "EGVD959888_2018-05-14                             NaN   \n",
       "EGVD961237_2009-04-20                             NaN   \n",
       "EGVD961237_2014-06-25                             NaN   \n",
       "EGVD990020_2016-04-04                             NaN   \n",
       "EGVD999649_2013-04-16                             NaN   \n",
       "\n",
       "                       stdprov_Urgent Care Facility_count  \\\n",
       "id                                                          \n",
       "EGVD004251_2007-12-18                                   0   \n",
       "EGVD008736_2019-05-31                                   0   \n",
       "EGVD010712_2005-04-13                                   0   \n",
       "EGVD011701_2005-01-24                                   0   \n",
       "EGVD015490_2019-09-16                                   0   \n",
       "...                                                   ...   \n",
       "EGVD959888_2018-05-14                                   1   \n",
       "EGVD961237_2009-04-20                                   0   \n",
       "EGVD961237_2014-06-25                                   0   \n",
       "EGVD990020_2016-04-04                                   0   \n",
       "EGVD999649_2013-04-16                                   0   \n",
       "\n",
       "                       stdprov_Urology_count  stdprov_Vision Center_count  \\\n",
       "id                                                                          \n",
       "EGVD004251_2007-12-18                      0                          NaN   \n",
       "EGVD008736_2019-05-31                      0                          NaN   \n",
       "EGVD010712_2005-04-13                      0                          NaN   \n",
       "EGVD011701_2005-01-24                      0                          NaN   \n",
       "EGVD015490_2019-09-16                      0                          NaN   \n",
       "...                                      ...                          ...   \n",
       "EGVD959888_2018-05-14                      0                          NaN   \n",
       "EGVD961237_2009-04-20                      0                          NaN   \n",
       "EGVD961237_2014-06-25                      0                          NaN   \n",
       "EGVD990020_2016-04-04                      0                          NaN   \n",
       "EGVD999649_2013-04-16                      0                          NaN   \n",
       "\n",
       "                       treatment_arm  \n",
       "id                                    \n",
       "EGVD004251_2007-12-18            NaN  \n",
       "EGVD008736_2019-05-31            NaN  \n",
       "EGVD010712_2005-04-13            NaN  \n",
       "EGVD011701_2005-01-24            NaN  \n",
       "EGVD015490_2019-09-16            NaN  \n",
       "...                              ...  \n",
       "EGVD959888_2018-05-14            NaN  \n",
       "EGVD961237_2009-04-20            NaN  \n",
       "EGVD961237_2014-06-25            NaN  \n",
       "EGVD990020_2016-04-04            NaN  \n",
       "EGVD999649_2013-04-16            NaN  \n",
       "\n",
       "[588 rows x 751 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can also use the model for training using it's fit method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_columns_1(X, imputed_values,replace_mean=True):\n",
    "    \"\"\"\n",
    "    Add X with missing columns, the values entered are the mean values\n",
    "    Args:\n",
    "        X (pd.DataFrame): The feature matrix\n",
    "        imputed_values (pd.DataFrame): A the mean feature values of each drug data set\n",
    "    Returns:\n",
    "        pd.DataFrame: An imputed data frame\n",
    "    \"\"\"\n",
    "    impute_cols = set(imputed_values.index) - set(X.columns)\n",
    "    for col in impute_cols:\n",
    "        if replace_mean:\n",
    "            X[col] = imputed_values[col]\n",
    "        else:\n",
    "            X[col] = np.nan\n",
    "    return X.loc[:, imputed_values.index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess_1(X, impute_drug=None, impute_file_name=f'../csv/mean_pred_cals.csv',replace_mean=True):\n",
    "    \"\"\"\n",
    "    load the data and impute it if required\n",
    "    Args:\n",
    "        data_file_name (str): The location of a pickle containing  a dictionary with two keys\n",
    "        one X the data set and another y the outcomes\n",
    "        impute_drug (str, optional): The drug to impute by Defaults to None.\n",
    "        impute_file_name (str, optional): the location of the impute data. Defaults to f'../csv/mean_pred_cals.csv'.\n",
    "    Returns:\n",
    "        tuple: a tuple where the first element is the imputed data frame and the second is the outcome\n",
    "    \"\"\"\n",
    "    impute_data = pd.read_csv(impute_file_name, index_col=0)\n",
    "    display(impute_data)\n",
    "    if not impute_drug is None:\n",
    "        print(impute_drug)\n",
    "        X = impute_columns_1(X, impute_data.loc[impute_drug.lower(), :],replace_mean=replace_mean)\n",
    "    return X.loc[:, impute_data.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ADMISSION_EP_count</th>\n",
       "      <th>ADMISSION_EP_daysToInddate_min</th>\n",
       "      <th>ADMISSION_EP_indicator</th>\n",
       "      <th>ANY_ADVERSE_EVENT_EP_count</th>\n",
       "      <th>ANY_ADVERSE_EVENT_EP_daysToInddate_min</th>\n",
       "      <th>ANY_ADVERSE_EVENT_EP_indicator</th>\n",
       "      <th>ANY_EEG_count</th>\n",
       "      <th>ANY_EEG_daysToInddate_min</th>\n",
       "      <th>ANY_EEG_indicator</th>\n",
       "      <th>...</th>\n",
       "      <th>stdprov_Therapy (Physical)_count</th>\n",
       "      <th>stdprov_Thoracic Surgery_count</th>\n",
       "      <th>stdprov_Transplant Surgery_count</th>\n",
       "      <th>stdprov_Transportation_count</th>\n",
       "      <th>stdprov_Traumatic Surgery_count</th>\n",
       "      <th>stdprov_Treatment Center_count</th>\n",
       "      <th>stdprov_Urgent Care Facility_count</th>\n",
       "      <th>stdprov_Urology_count</th>\n",
       "      <th>stdprov_Vision Center_count</th>\n",
       "      <th>treatment_arm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>carbamazepine</td>\n",
       "      <td>0.070428</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>valproate</td>\n",
       "      <td>0.104927</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oxcarbazepine</td>\n",
       "      <td>0.143192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lamotrigine</td>\n",
       "      <td>0.106131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>levetiracetam</td>\n",
       "      <td>0.165251</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>topiramate</td>\n",
       "      <td>0.068354</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gabapentin</td>\n",
       "      <td>0.040755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>phenytoin</td>\n",
       "      <td>0.166232</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 752 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  ADMISSION_EP_count  ADMISSION_EP_daysToInddate_min  \\\n",
       "0  carbamazepine            0.070428                             NaN   \n",
       "1      valproate            0.104927                             NaN   \n",
       "2  oxcarbazepine            0.143192                             NaN   \n",
       "3    lamotrigine            0.106131                             NaN   \n",
       "4  levetiracetam            0.165251                             NaN   \n",
       "5     topiramate            0.068354                             NaN   \n",
       "6     gabapentin            0.040755                             NaN   \n",
       "7      phenytoin            0.166232                             NaN   \n",
       "\n",
       "   ADMISSION_EP_indicator  ANY_ADVERSE_EVENT_EP_count  \\\n",
       "0                     NaN                         NaN   \n",
       "1                     NaN                         NaN   \n",
       "2                     NaN                         NaN   \n",
       "3                     NaN                         NaN   \n",
       "4                     NaN                         NaN   \n",
       "5                     NaN                         NaN   \n",
       "6                     NaN                         NaN   \n",
       "7                     NaN                         NaN   \n",
       "\n",
       "   ANY_ADVERSE_EVENT_EP_daysToInddate_min  ANY_ADVERSE_EVENT_EP_indicator  \\\n",
       "0                                     NaN                             NaN   \n",
       "1                                     NaN                             NaN   \n",
       "2                                     NaN                             NaN   \n",
       "3                                     NaN                             NaN   \n",
       "4                                     NaN                             NaN   \n",
       "5                                     NaN                             NaN   \n",
       "6                                     NaN                             NaN   \n",
       "7                                     NaN                             NaN   \n",
       "\n",
       "   ANY_EEG_count  ANY_EEG_daysToInddate_min  ANY_EEG_indicator  ...  \\\n",
       "0            NaN                        NaN                NaN  ...   \n",
       "1            NaN                        NaN                NaN  ...   \n",
       "2            NaN                        NaN                NaN  ...   \n",
       "3            NaN                        NaN                NaN  ...   \n",
       "4            NaN                        NaN                NaN  ...   \n",
       "5            NaN                        NaN                NaN  ...   \n",
       "6            NaN                        NaN                NaN  ...   \n",
       "7            NaN                        NaN                NaN  ...   \n",
       "\n",
       "   stdprov_Therapy (Physical)_count  stdprov_Thoracic Surgery_count  \\\n",
       "0                               NaN                             NaN   \n",
       "1                               NaN                             NaN   \n",
       "2                               NaN                             NaN   \n",
       "3                               NaN                             NaN   \n",
       "4                               NaN                             NaN   \n",
       "5                               NaN                             NaN   \n",
       "6                               NaN                             NaN   \n",
       "7                               NaN                             NaN   \n",
       "\n",
       "   stdprov_Transplant Surgery_count  stdprov_Transportation_count  \\\n",
       "0                               NaN                           NaN   \n",
       "1                               NaN                           NaN   \n",
       "2                               NaN                           NaN   \n",
       "3                               NaN                           NaN   \n",
       "4                               NaN                           NaN   \n",
       "5                               NaN                           NaN   \n",
       "6                               NaN                           NaN   \n",
       "7                               NaN                           NaN   \n",
       "\n",
       "   stdprov_Traumatic Surgery_count  stdprov_Treatment Center_count  \\\n",
       "0                              NaN                             NaN   \n",
       "1                              NaN                             NaN   \n",
       "2                              NaN                             NaN   \n",
       "3                              NaN                             NaN   \n",
       "4                              NaN                             NaN   \n",
       "5                              NaN                             NaN   \n",
       "6                              NaN                             NaN   \n",
       "7                              NaN                             NaN   \n",
       "\n",
       "   stdprov_Urgent Care Facility_count  stdprov_Urology_count  \\\n",
       "0                                 NaN                    NaN   \n",
       "1                                 NaN                    NaN   \n",
       "2                                 NaN                    NaN   \n",
       "3                                 NaN                    NaN   \n",
       "4                                 NaN                    NaN   \n",
       "5                                 NaN                    NaN   \n",
       "6                                 NaN                    NaN   \n",
       "7                                 NaN                    NaN   \n",
       "\n",
       "   stdprov_Vision Center_count  treatment_arm  \n",
       "0                          NaN            NaN  \n",
       "1                          NaN            NaN  \n",
       "2                          NaN            NaN  \n",
       "3                          NaN            NaN  \n",
       "4                          NaN            NaN  \n",
       "5                          NaN            NaN  \n",
       "6                          NaN            NaN  \n",
       "7                          NaN            NaN  \n",
       "\n",
       "[8 rows x 752 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_csv('../csv/mean_pred_cals.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'carbamazepine'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADMISSION_EP_count</th>\n",
       "      <th>ADMISSION_EP_daysToInddate_min</th>\n",
       "      <th>ADMISSION_EP_indicator</th>\n",
       "      <th>ANY_ADVERSE_EVENT_EP_count</th>\n",
       "      <th>ANY_ADVERSE_EVENT_EP_daysToInddate_min</th>\n",
       "      <th>ANY_ADVERSE_EVENT_EP_indicator</th>\n",
       "      <th>ANY_EEG_count</th>\n",
       "      <th>ANY_EEG_daysToInddate_min</th>\n",
       "      <th>ANY_EEG_indicator</th>\n",
       "      <th>CARBAMAZEPINE_daysToInddate_min</th>\n",
       "      <th>...</th>\n",
       "      <th>stdprov_Therapy (Physical)_count</th>\n",
       "      <th>stdprov_Thoracic Surgery_count</th>\n",
       "      <th>stdprov_Transplant Surgery_count</th>\n",
       "      <th>stdprov_Transportation_count</th>\n",
       "      <th>stdprov_Traumatic Surgery_count</th>\n",
       "      <th>stdprov_Treatment Center_count</th>\n",
       "      <th>stdprov_Urgent Care Facility_count</th>\n",
       "      <th>stdprov_Urology_count</th>\n",
       "      <th>stdprov_Vision Center_count</th>\n",
       "      <th>treatment_arm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>carbamazepine</th>\n",
       "      <td>0.070428</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valproate</th>\n",
       "      <td>0.104927</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oxcarbazepine</th>\n",
       "      <td>0.143192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lamotrigine</th>\n",
       "      <td>0.106131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>levetiracetam</th>\n",
       "      <td>0.165251</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topiramate</th>\n",
       "      <td>0.068354</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gabapentin</th>\n",
       "      <td>0.040755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phenytoin</th>\n",
       "      <td>0.166232</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 751 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ADMISSION_EP_count  ADMISSION_EP_daysToInddate_min  \\\n",
       "carbamazepine            0.070428                             NaN   \n",
       "valproate                0.104927                             NaN   \n",
       "oxcarbazepine            0.143192                             NaN   \n",
       "lamotrigine              0.106131                             NaN   \n",
       "levetiracetam            0.165251                             NaN   \n",
       "topiramate               0.068354                             NaN   \n",
       "gabapentin               0.040755                             NaN   \n",
       "phenytoin                0.166232                             NaN   \n",
       "\n",
       "               ADMISSION_EP_indicator  ANY_ADVERSE_EVENT_EP_count  \\\n",
       "carbamazepine                     NaN                         NaN   \n",
       "valproate                         NaN                         NaN   \n",
       "oxcarbazepine                     NaN                         NaN   \n",
       "lamotrigine                       NaN                         NaN   \n",
       "levetiracetam                     NaN                         NaN   \n",
       "topiramate                        NaN                         NaN   \n",
       "gabapentin                        NaN                         NaN   \n",
       "phenytoin                         NaN                         NaN   \n",
       "\n",
       "               ANY_ADVERSE_EVENT_EP_daysToInddate_min  \\\n",
       "carbamazepine                                     NaN   \n",
       "valproate                                         NaN   \n",
       "oxcarbazepine                                     NaN   \n",
       "lamotrigine                                       NaN   \n",
       "levetiracetam                                     NaN   \n",
       "topiramate                                        NaN   \n",
       "gabapentin                                        NaN   \n",
       "phenytoin                                         NaN   \n",
       "\n",
       "               ANY_ADVERSE_EVENT_EP_indicator  ANY_EEG_count  \\\n",
       "carbamazepine                             NaN            NaN   \n",
       "valproate                                 NaN            NaN   \n",
       "oxcarbazepine                             NaN            NaN   \n",
       "lamotrigine                               NaN            NaN   \n",
       "levetiracetam                             NaN            NaN   \n",
       "topiramate                                NaN            NaN   \n",
       "gabapentin                                NaN            NaN   \n",
       "phenytoin                                 NaN            NaN   \n",
       "\n",
       "               ANY_EEG_daysToInddate_min  ANY_EEG_indicator  \\\n",
       "carbamazepine                        NaN                NaN   \n",
       "valproate                            NaN                NaN   \n",
       "oxcarbazepine                        NaN                NaN   \n",
       "lamotrigine                          NaN                NaN   \n",
       "levetiracetam                        NaN                NaN   \n",
       "topiramate                           NaN                NaN   \n",
       "gabapentin                           NaN                NaN   \n",
       "phenytoin                            NaN                NaN   \n",
       "\n",
       "               CARBAMAZEPINE_daysToInddate_min  ...  \\\n",
       "carbamazepine                              NaN  ...   \n",
       "valproate                                  NaN  ...   \n",
       "oxcarbazepine                              NaN  ...   \n",
       "lamotrigine                                NaN  ...   \n",
       "levetiracetam                              NaN  ...   \n",
       "topiramate                                 NaN  ...   \n",
       "gabapentin                                 NaN  ...   \n",
       "phenytoin                                  NaN  ...   \n",
       "\n",
       "               stdprov_Therapy (Physical)_count  \\\n",
       "carbamazepine                               NaN   \n",
       "valproate                                   NaN   \n",
       "oxcarbazepine                               NaN   \n",
       "lamotrigine                                 NaN   \n",
       "levetiracetam                               NaN   \n",
       "topiramate                                  NaN   \n",
       "gabapentin                                  NaN   \n",
       "phenytoin                                   NaN   \n",
       "\n",
       "               stdprov_Thoracic Surgery_count  \\\n",
       "carbamazepine                             NaN   \n",
       "valproate                                 NaN   \n",
       "oxcarbazepine                             NaN   \n",
       "lamotrigine                               NaN   \n",
       "levetiracetam                             NaN   \n",
       "topiramate                                NaN   \n",
       "gabapentin                                NaN   \n",
       "phenytoin                                 NaN   \n",
       "\n",
       "               stdprov_Transplant Surgery_count  stdprov_Transportation_count  \\\n",
       "carbamazepine                               NaN                           NaN   \n",
       "valproate                                   NaN                           NaN   \n",
       "oxcarbazepine                               NaN                           NaN   \n",
       "lamotrigine                                 NaN                           NaN   \n",
       "levetiracetam                               NaN                           NaN   \n",
       "topiramate                                  NaN                           NaN   \n",
       "gabapentin                                  NaN                           NaN   \n",
       "phenytoin                                   NaN                           NaN   \n",
       "\n",
       "               stdprov_Traumatic Surgery_count  \\\n",
       "carbamazepine                              NaN   \n",
       "valproate                                  NaN   \n",
       "oxcarbazepine                              NaN   \n",
       "lamotrigine                                NaN   \n",
       "levetiracetam                              NaN   \n",
       "topiramate                                 NaN   \n",
       "gabapentin                                 NaN   \n",
       "phenytoin                                  NaN   \n",
       "\n",
       "               stdprov_Treatment Center_count  \\\n",
       "carbamazepine                             NaN   \n",
       "valproate                                 NaN   \n",
       "oxcarbazepine                             NaN   \n",
       "lamotrigine                               NaN   \n",
       "levetiracetam                             NaN   \n",
       "topiramate                                NaN   \n",
       "gabapentin                                NaN   \n",
       "phenytoin                                 NaN   \n",
       "\n",
       "               stdprov_Urgent Care Facility_count  stdprov_Urology_count  \\\n",
       "carbamazepine                                 NaN                    NaN   \n",
       "valproate                                     NaN                    NaN   \n",
       "oxcarbazepine                                 NaN                    NaN   \n",
       "lamotrigine                                   NaN                    NaN   \n",
       "levetiracetam                                 NaN                    NaN   \n",
       "topiramate                                    NaN                    NaN   \n",
       "gabapentin                                    NaN                    NaN   \n",
       "phenytoin                                     NaN                    NaN   \n",
       "\n",
       "               stdprov_Vision Center_count  treatment_arm  \n",
       "carbamazepine                          NaN            NaN  \n",
       "valproate                              NaN            NaN  \n",
       "oxcarbazepine                          NaN            NaN  \n",
       "lamotrigine                            NaN            NaN  \n",
       "levetiracetam                          NaN            NaN  \n",
       "topiramate                             NaN            NaN  \n",
       "gabapentin                             NaN            NaN  \n",
       "phenytoin                              NaN            NaN  \n",
       "\n",
       "[8 rows x 751 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carbamazepine\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADMISSION_EP_count</th>\n",
       "      <th>ADMISSION_EP_daysToInddate_min</th>\n",
       "      <th>ADMISSION_EP_indicator</th>\n",
       "      <th>ANY_ADVERSE_EVENT_EP_count</th>\n",
       "      <th>ANY_ADVERSE_EVENT_EP_daysToInddate_min</th>\n",
       "      <th>ANY_ADVERSE_EVENT_EP_indicator</th>\n",
       "      <th>ANY_EEG_count</th>\n",
       "      <th>ANY_EEG_daysToInddate_min</th>\n",
       "      <th>ANY_EEG_indicator</th>\n",
       "      <th>CARBAMAZEPINE_daysToInddate_min</th>\n",
       "      <th>...</th>\n",
       "      <th>stdprov_Therapy (Physical)_count</th>\n",
       "      <th>stdprov_Thoracic Surgery_count</th>\n",
       "      <th>stdprov_Transplant Surgery_count</th>\n",
       "      <th>stdprov_Transportation_count</th>\n",
       "      <th>stdprov_Traumatic Surgery_count</th>\n",
       "      <th>stdprov_Treatment Center_count</th>\n",
       "      <th>stdprov_Urgent Care Facility_count</th>\n",
       "      <th>stdprov_Urology_count</th>\n",
       "      <th>stdprov_Vision Center_count</th>\n",
       "      <th>treatment_arm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EGVD011444_2013-07-24</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGVD015050_2012-05-24</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGVD017943_2005-09-05</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGVD020081_2006-06-15</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGVD020784_2009-06-16</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGVD956438_2016-04-22</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGVD959884_2017-05-15</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGVD970807_2008-02-25</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGVD975311_2010-10-06</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGVD993650_2015-12-21</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows × 751 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ADMISSION_EP_count  ADMISSION_EP_daysToInddate_min  \\\n",
       "id                                                                          \n",
       "EGVD011444_2013-07-24                   0                             NaN   \n",
       "EGVD015050_2012-05-24                   0                             NaN   \n",
       "EGVD017943_2005-09-05                   0                             NaN   \n",
       "EGVD020081_2006-06-15                   0                             NaN   \n",
       "EGVD020784_2009-06-16                   0                             NaN   \n",
       "...                                   ...                             ...   \n",
       "EGVD956438_2016-04-22                   0                             NaN   \n",
       "EGVD959884_2017-05-15                   0                             NaN   \n",
       "EGVD970807_2008-02-25                   1                             NaN   \n",
       "EGVD975311_2010-10-06                   0                             NaN   \n",
       "EGVD993650_2015-12-21                   0                             NaN   \n",
       "\n",
       "                       ADMISSION_EP_indicator  ANY_ADVERSE_EVENT_EP_count  \\\n",
       "id                                                                          \n",
       "EGVD011444_2013-07-24                   False                         NaN   \n",
       "EGVD015050_2012-05-24                   False                         NaN   \n",
       "EGVD017943_2005-09-05                   False                         NaN   \n",
       "EGVD020081_2006-06-15                   False                         NaN   \n",
       "EGVD020784_2009-06-16                   False                         NaN   \n",
       "...                                       ...                         ...   \n",
       "EGVD956438_2016-04-22                   False                         NaN   \n",
       "EGVD959884_2017-05-15                   False                         NaN   \n",
       "EGVD970807_2008-02-25                    True                         NaN   \n",
       "EGVD975311_2010-10-06                   False                         NaN   \n",
       "EGVD993650_2015-12-21                   False                         NaN   \n",
       "\n",
       "                       ANY_ADVERSE_EVENT_EP_daysToInddate_min  \\\n",
       "id                                                              \n",
       "EGVD011444_2013-07-24                                     NaN   \n",
       "EGVD015050_2012-05-24                                     NaN   \n",
       "EGVD017943_2005-09-05                                     NaN   \n",
       "EGVD020081_2006-06-15                                     NaN   \n",
       "EGVD020784_2009-06-16                                     NaN   \n",
       "...                                                       ...   \n",
       "EGVD956438_2016-04-22                                     NaN   \n",
       "EGVD959884_2017-05-15                                     NaN   \n",
       "EGVD970807_2008-02-25                                     NaN   \n",
       "EGVD975311_2010-10-06                                     NaN   \n",
       "EGVD993650_2015-12-21                                     NaN   \n",
       "\n",
       "                       ANY_ADVERSE_EVENT_EP_indicator  ANY_EEG_count  \\\n",
       "id                                                                     \n",
       "EGVD011444_2013-07-24                             NaN            NaN   \n",
       "EGVD015050_2012-05-24                             NaN            NaN   \n",
       "EGVD017943_2005-09-05                             NaN            NaN   \n",
       "EGVD020081_2006-06-15                             NaN            NaN   \n",
       "EGVD020784_2009-06-16                             NaN            NaN   \n",
       "...                                               ...            ...   \n",
       "EGVD956438_2016-04-22                             NaN            NaN   \n",
       "EGVD959884_2017-05-15                             NaN            NaN   \n",
       "EGVD970807_2008-02-25                             NaN            NaN   \n",
       "EGVD975311_2010-10-06                             NaN            NaN   \n",
       "EGVD993650_2015-12-21                             NaN            NaN   \n",
       "\n",
       "                       ANY_EEG_daysToInddate_min  ANY_EEG_indicator  \\\n",
       "id                                                                    \n",
       "EGVD011444_2013-07-24                        NaN                NaN   \n",
       "EGVD015050_2012-05-24                        NaN                NaN   \n",
       "EGVD017943_2005-09-05                        NaN                NaN   \n",
       "EGVD020081_2006-06-15                        NaN                NaN   \n",
       "EGVD020784_2009-06-16                        NaN                NaN   \n",
       "...                                          ...                ...   \n",
       "EGVD956438_2016-04-22                        NaN                NaN   \n",
       "EGVD959884_2017-05-15                        NaN                NaN   \n",
       "EGVD970807_2008-02-25                        NaN                NaN   \n",
       "EGVD975311_2010-10-06                        NaN                NaN   \n",
       "EGVD993650_2015-12-21                        NaN                NaN   \n",
       "\n",
       "                       CARBAMAZEPINE_daysToInddate_min  ...  \\\n",
       "id                                                      ...   \n",
       "EGVD011444_2013-07-24                              NaN  ...   \n",
       "EGVD015050_2012-05-24                              NaN  ...   \n",
       "EGVD017943_2005-09-05                              NaN  ...   \n",
       "EGVD020081_2006-06-15                              NaN  ...   \n",
       "EGVD020784_2009-06-16                              NaN  ...   \n",
       "...                                                ...  ...   \n",
       "EGVD956438_2016-04-22                              NaN  ...   \n",
       "EGVD959884_2017-05-15                              NaN  ...   \n",
       "EGVD970807_2008-02-25                              NaN  ...   \n",
       "EGVD975311_2010-10-06                              NaN  ...   \n",
       "EGVD993650_2015-12-21                              NaN  ...   \n",
       "\n",
       "                       stdprov_Therapy (Physical)_count  \\\n",
       "id                                                        \n",
       "EGVD011444_2013-07-24                                 0   \n",
       "EGVD015050_2012-05-24                                 0   \n",
       "EGVD017943_2005-09-05                                 0   \n",
       "EGVD020081_2006-06-15                                 0   \n",
       "EGVD020784_2009-06-16                                 0   \n",
       "...                                                 ...   \n",
       "EGVD956438_2016-04-22                                 0   \n",
       "EGVD959884_2017-05-15                                 0   \n",
       "EGVD970807_2008-02-25                                 0   \n",
       "EGVD975311_2010-10-06                                 0   \n",
       "EGVD993650_2015-12-21                                 0   \n",
       "\n",
       "                       stdprov_Thoracic Surgery_count  \\\n",
       "id                                                      \n",
       "EGVD011444_2013-07-24                               0   \n",
       "EGVD015050_2012-05-24                               0   \n",
       "EGVD017943_2005-09-05                               0   \n",
       "EGVD020081_2006-06-15                               0   \n",
       "EGVD020784_2009-06-16                               0   \n",
       "...                                               ...   \n",
       "EGVD956438_2016-04-22                               0   \n",
       "EGVD959884_2017-05-15                               0   \n",
       "EGVD970807_2008-02-25                               0   \n",
       "EGVD975311_2010-10-06                               0   \n",
       "EGVD993650_2015-12-21                               0   \n",
       "\n",
       "                       stdprov_Transplant Surgery_count  \\\n",
       "id                                                        \n",
       "EGVD011444_2013-07-24                               NaN   \n",
       "EGVD015050_2012-05-24                               NaN   \n",
       "EGVD017943_2005-09-05                               NaN   \n",
       "EGVD020081_2006-06-15                               NaN   \n",
       "EGVD020784_2009-06-16                               NaN   \n",
       "...                                                 ...   \n",
       "EGVD956438_2016-04-22                               NaN   \n",
       "EGVD959884_2017-05-15                               NaN   \n",
       "EGVD970807_2008-02-25                               NaN   \n",
       "EGVD975311_2010-10-06                               NaN   \n",
       "EGVD993650_2015-12-21                               NaN   \n",
       "\n",
       "                       stdprov_Transportation_count  \\\n",
       "id                                                    \n",
       "EGVD011444_2013-07-24                           NaN   \n",
       "EGVD015050_2012-05-24                           NaN   \n",
       "EGVD017943_2005-09-05                           NaN   \n",
       "EGVD020081_2006-06-15                           NaN   \n",
       "EGVD020784_2009-06-16                           NaN   \n",
       "...                                             ...   \n",
       "EGVD956438_2016-04-22                           NaN   \n",
       "EGVD959884_2017-05-15                           NaN   \n",
       "EGVD970807_2008-02-25                           NaN   \n",
       "EGVD975311_2010-10-06                           NaN   \n",
       "EGVD993650_2015-12-21                           NaN   \n",
       "\n",
       "                       stdprov_Traumatic Surgery_count  \\\n",
       "id                                                       \n",
       "EGVD011444_2013-07-24                              NaN   \n",
       "EGVD015050_2012-05-24                              NaN   \n",
       "EGVD017943_2005-09-05                              NaN   \n",
       "EGVD020081_2006-06-15                              NaN   \n",
       "EGVD020784_2009-06-16                              NaN   \n",
       "...                                                ...   \n",
       "EGVD956438_2016-04-22                              NaN   \n",
       "EGVD959884_2017-05-15                              NaN   \n",
       "EGVD970807_2008-02-25                              NaN   \n",
       "EGVD975311_2010-10-06                              NaN   \n",
       "EGVD993650_2015-12-21                              NaN   \n",
       "\n",
       "                       stdprov_Treatment Center_count  \\\n",
       "id                                                      \n",
       "EGVD011444_2013-07-24                             NaN   \n",
       "EGVD015050_2012-05-24                             NaN   \n",
       "EGVD017943_2005-09-05                             NaN   \n",
       "EGVD020081_2006-06-15                             NaN   \n",
       "EGVD020784_2009-06-16                             NaN   \n",
       "...                                               ...   \n",
       "EGVD956438_2016-04-22                             NaN   \n",
       "EGVD959884_2017-05-15                             NaN   \n",
       "EGVD970807_2008-02-25                             NaN   \n",
       "EGVD975311_2010-10-06                             NaN   \n",
       "EGVD993650_2015-12-21                             NaN   \n",
       "\n",
       "                       stdprov_Urgent Care Facility_count  \\\n",
       "id                                                          \n",
       "EGVD011444_2013-07-24                                   0   \n",
       "EGVD015050_2012-05-24                                   0   \n",
       "EGVD017943_2005-09-05                                   0   \n",
       "EGVD020081_2006-06-15                                   0   \n",
       "EGVD020784_2009-06-16                                   0   \n",
       "...                                                   ...   \n",
       "EGVD956438_2016-04-22                                   1   \n",
       "EGVD959884_2017-05-15                                   0   \n",
       "EGVD970807_2008-02-25                                   0   \n",
       "EGVD975311_2010-10-06                                   0   \n",
       "EGVD993650_2015-12-21                                   0   \n",
       "\n",
       "                       stdprov_Urology_count  stdprov_Vision Center_count  \\\n",
       "id                                                                          \n",
       "EGVD011444_2013-07-24                      0                          NaN   \n",
       "EGVD015050_2012-05-24                      0                          NaN   \n",
       "EGVD017943_2005-09-05                      0                          NaN   \n",
       "EGVD020081_2006-06-15                      0                          NaN   \n",
       "EGVD020784_2009-06-16                      0                          NaN   \n",
       "...                                      ...                          ...   \n",
       "EGVD956438_2016-04-22                      0                          NaN   \n",
       "EGVD959884_2017-05-15                      1                          NaN   \n",
       "EGVD970807_2008-02-25                      0                          NaN   \n",
       "EGVD975311_2010-10-06                      0                          NaN   \n",
       "EGVD993650_2015-12-21                      0                          NaN   \n",
       "\n",
       "                       treatment_arm  \n",
       "id                                    \n",
       "EGVD011444_2013-07-24            NaN  \n",
       "EGVD015050_2012-05-24            NaN  \n",
       "EGVD017943_2005-09-05            NaN  \n",
       "EGVD020081_2006-06-15            NaN  \n",
       "EGVD020784_2009-06-16            NaN  \n",
       "...                              ...  \n",
       "EGVD956438_2016-04-22            NaN  \n",
       "EGVD959884_2017-05-15            NaN  \n",
       "EGVD970807_2008-02-25            NaN  \n",
       "EGVD975311_2010-10-06            NaN  \n",
       "EGVD993650_2015-12-21            NaN  \n",
       "\n",
       "[392 rows x 751 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_preprocess_1(X_test,impute_drug=drug_name, impute_file_name='õige asukoht' replace_mean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.3,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=&#x27;logloss&#x27;, gamma=0.4, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=&#x27;gain&#x27;,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.05, max_bin=256,\n",
       "              max_cat_to_onehot=4, max_delta_step=0, max_depth=4, max_leaves=0,\n",
       "              min_child_weight=5, missing=nan, monotone_constraints=&#x27;()&#x27;,\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, predictor=&#x27;auto&#x27;,\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.3,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=&#x27;logloss&#x27;, gamma=0.4, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=&#x27;gain&#x27;,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.05, max_bin=256,\n",
       "              max_cat_to_onehot=4, max_delta_step=0, max_depth=4, max_leaves=0,\n",
       "              min_child_weight=5, missing=nan, monotone_constraints=&#x27;()&#x27;,\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, predictor=&#x27;auto&#x27;,\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.3,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric='logloss', gamma=0.4, gpu_id=-1,\n",
       "              grow_policy='depthwise', importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.05, max_bin=256,\n",
       "              max_cat_to_onehot=4, max_delta_step=0, max_depth=4, max_leaves=0,\n",
       "              min_child_weight=5, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, predictor='auto',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_clf = deepcopy(clf)\n",
    "new_clf.fit(X,y_train)\n",
    "#new_clf.save_model('../models/prediction/est_carba_p.xgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval = evaluate_model(clf,new_clf,Xs,y_test)\n",
    "rep = fuse_string(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc1: 0.57 (upper: 0.65, lower: 0.48) \n",
      " auc2: 0.65 (upper: 0.73, lower: 0.56) \n",
      " mcnemar_test: p-value 1.000 \n",
      " delong_test: p-value 0.127 \n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outcome primary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n",
      "c:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\utils.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[col] = imputed_values[col]\n"
     ]
    }
   ],
   "source": [
    "data_file_name = r\"C:\\\\Users\\Anastassia Kolde\\\\Documents\\\\Israel secondment\\\\Data\\test_train_epilepsy_19.01.23.csv\"\n",
    "X_train,y_train,X_test,y_test = load_data(change_name_file,data_file_name, outcome_col=\"outcome_primary\")\n",
    "drug_name=\"carbamazepine\"\n",
    "clf = load_prediction_model(drug_name)\n",
    "X = data_preprocess(X_train,impute_drug=drug_name)\n",
    "Xs = data_preprocess(X_test,impute_drug=drug_name)\n",
    "new_clf = deepcopy(clf)\n",
    "new_clf.fit(X,y_train)\n",
    "#new_clf.save_model('../models/prediction/est_carba_new_out.xgb')\n",
    "eval = evaluate_model(clf,new_clf,Xs,y_test)\n",
    "rep = fuse_string(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc1: 0.54 (upper: 0.68, lower: 0.39) \n",
      " auc2: 0.55 (upper: 0.68, lower: 0.41) \n",
      " mcnemar_test: p-value 1.000 \n",
      " delong_test: p-value 0.890 \n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the regressor imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\AnacondaEnvs\\epilepsy\\lib\\site-packages\\sklearn\\base.py:288: UserWarning: Trying to unpickle estimator LassoCV from version 1.1.2 when using version 1.2.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\AnacondaEnvs\\epilepsy\\lib\\site-packages\\sklearn\\base.py:288: UserWarning: Trying to unpickle estimator LogisticRegression from version 1.1.2 when using version 1.2.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\AnacondaEnvs\\epilepsy\\lib\\site-packages\\sklearn\\base.py:288: UserWarning: Trying to unpickle estimator GridSearchCV from version 1.1.2 when using version 1.2.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#col_imputer = load_imputation_model(\"col_carbamazepine\")\n",
    "regress_imputer = load_imputation_model(\"regress_imputer_carbamazepine.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do we have nan value !: True\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLassoCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m Xs \u001b[38;5;241m=\u001b[39m data_preprocess(X_test,impute_drug\u001b[38;5;241m=\u001b[39mdrug_name,replace_mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDo we have nan value !:\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;28many\u001b[39m(X\u001b[38;5;241m.\u001b[39misnull()))\n\u001b[1;32m----> 4\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mregress_imputer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m Xs \u001b[38;5;241m=\u001b[39m regress_imputer\u001b[38;5;241m.\u001b[39mtransform(Xs)\n\u001b[0;32m      6\u001b[0m new_clf \u001b[38;5;241m=\u001b[39m deepcopy(clf)\n",
      "File \u001b[1;32mc:\\users\\anastassia kolde\\documents\\github\\unstableepilepsy\\epilepsy_prediction\\epilepsy_prediction\\imputation.py:76\u001b[0m, in \u001b[0;36mregress_missing_imputer.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(X[col]\u001b[38;5;241m.\u001b[39misnull()):\n\u001b[0;32m     75\u001b[0m         X_pred,_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_data_set(X,col,isnull\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 76\u001b[0m         X\u001b[38;5;241m.\u001b[39mloc[X[col]\u001b[38;5;241m.\u001b[39misnull(),col] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "File \u001b[1;32mC:\\ProgramData\\AnacondaEnvs\\epilepsy\\lib\\site-packages\\sklearn\\linear_model\\_base.py:355\u001b[0m, in \u001b[0;36mLinearModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;124;03m    Predict using the linear model.\u001b[39;00m\n\u001b[0;32m    344\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;124;03m        Returns predicted values.\u001b[39;00m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\AnacondaEnvs\\epilepsy\\lib\\site-packages\\sklearn\\linear_model\\_base.py:338\u001b[0m, in \u001b[0;36mLinearModel._decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    336\u001b[0m     check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 338\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n",
      "File \u001b[1;32mC:\\ProgramData\\AnacondaEnvs\\epilepsy\\lib\\site-packages\\sklearn\\base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 535\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    536\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32mC:\\ProgramData\\AnacondaEnvs\\epilepsy\\lib\\site-packages\\sklearn\\utils\\validation.py:919\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    913\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    914\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    915\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    916\u001b[0m         )\n\u001b[0;32m    918\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 919\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    927\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32mC:\\ProgramData\\AnacondaEnvs\\epilepsy\\lib\\site-packages\\sklearn\\utils\\validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m     )\n\u001b[1;32m--> 161\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nLassoCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "X = data_preprocess(X_train,impute_drug=drug_name,replace_mean=False)\n",
    "Xs = data_preprocess(X_test,impute_drug=drug_name,replace_mean=False)\n",
    "print('Do we have nan value !:',any(X.isnull()))\n",
    "X = regress_imputer.transform(X)\n",
    "Xs = regress_imputer.transform(Xs)\n",
    "new_clf = deepcopy(clf)\n",
    "new_clf.fit(X,y_train)\n",
    "#new_clf.save_model('../models/prediction/est_carba_new_impute.xgb')\n",
    "eval = evaluate_model(clf,new_clf,Xs,y_test)\n",
    "rep = fuse_string(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rep)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "ddd9f49c652c6d182f69755b7ee5e124f86cbddecfc26f23757e5e4f41f4cab8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
